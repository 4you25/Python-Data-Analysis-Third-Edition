{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing CSV files with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import genfromtxt function\n",
    "from numpy import genfromtxt\n",
    "\n",
    "# Read comma separated file\n",
    "my_data = genfromtxt('my_file.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample array\n",
    "sample_array = np.asarray([ [1,2,3], [4,5,6], [7,8,9] ])\n",
    "\n",
    "# Write sample array to CSV file\n",
    "np.savetxt(\"my_first_file.csv\", sample_array, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing CSV files with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File my_sample_file.csv does not exist: 'my_sample_file.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-57e01c9facab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Read CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msample_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_sample_file.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File my_sample_file.csv does not exist: 'my_sample_file.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read CSV file\n",
    "sample_df=pd.read_csv('my_sample_file.csv', sep=',' , header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV file.\n",
    "sample_df_temp.to_csv('sample_df_temp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Data from Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read excel file\n",
    "df=pd.read_excel('file_name.xlsx', sheet_name='sheet_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('file_name.xlsx', sheet_name='sheet_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('file_name.xlsx') as writer:\n",
    "    first_df.to_excel(writer, sheet_name='first_sheet_title')\n",
    "    second_df.to_excel(writer, sheet_name='second_sheet_title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Data from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading JSON file\n",
    "df=pd.read_json('test.json')\n",
    "\n",
    "# Writing DataFrame to JSON file\n",
    "df.to_json(orient=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reading and Writing Data from HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read a hdf5 file\n",
    "df=pd.read_hdf('employee.h5', 'table')\n",
    "\n",
    "# Write DataFrame to hdf5\n",
    "df.to_hdf('employee.h5', 'table', append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Data from HTML Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of DataFrames: 8\n"
     ]
    }
   ],
   "source": [
    "# Reading HTML table from given URL\n",
    "table_url = 'https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_in_North_America'\n",
    "df_list = pd.read_html(table_url)\n",
    "print(\"Number of DataFrames:\",len(df_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flag</th>\n",
       "      <th>English short name</th>\n",
       "      <th>English long name</th>\n",
       "      <th>Domestic short name(s)</th>\n",
       "      <th>Capital</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Antigua and Barbuda[n 1]</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>English: Antigua and Barbuda</td>\n",
       "      <td>St. John's</td>\n",
       "      <td>East Caribbean dollar</td>\n",
       "      <td>Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bahamas, The[n 1]</td>\n",
       "      <td>Commonwealth of The Bahamas</td>\n",
       "      <td>English: Bahamas</td>\n",
       "      <td>Nassau</td>\n",
       "      <td>Bahamian dollar</td>\n",
       "      <td>Lucayan Archipelago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Barbados[n 1]</td>\n",
       "      <td>Barbados</td>\n",
       "      <td>English: Barbados</td>\n",
       "      <td>Bridgetown</td>\n",
       "      <td>Barbadian dollar</td>\n",
       "      <td>Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Belize[n 1][n 2]</td>\n",
       "      <td>Belize</td>\n",
       "      <td>English: Belize</td>\n",
       "      <td>Belmopan</td>\n",
       "      <td>Belize dollar</td>\n",
       "      <td>Central America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Canada[n 3]</td>\n",
       "      <td>Canada</td>\n",
       "      <td>English: CanadaFrench: Canada</td>\n",
       "      <td>Ottawa</td>\n",
       "      <td>Canadian dollar</td>\n",
       "      <td>Northern America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Flag        English short name            English long name  \\\n",
       "0   NaN  Antigua and Barbuda[n 1]          Antigua and Barbuda   \n",
       "1   NaN         Bahamas, The[n 1]  Commonwealth of The Bahamas   \n",
       "2   NaN             Barbados[n 1]                     Barbados   \n",
       "3   NaN          Belize[n 1][n 2]                       Belize   \n",
       "4   NaN               Canada[n 3]                       Canada   \n",
       "\n",
       "          Domestic short name(s)     Capital               Currency  \\\n",
       "0   English: Antigua and Barbuda  St. John's  East Caribbean dollar   \n",
       "1               English: Bahamas      Nassau        Bahamian dollar   \n",
       "2              English: Barbados  Bridgetown       Barbadian dollar   \n",
       "3                English: Belize    Belmopan          Belize dollar   \n",
       "4  English: CanadaFrench: Canada      Ottawa        Canadian dollar   \n",
       "\n",
       "              Location  \n",
       "0            Caribbean  \n",
       "1  Lucayan Archipelago  \n",
       "2            Caribbean  \n",
       "3      Central America  \n",
       "4     Northern America  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check first DataFrame\n",
    "df_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to raw HTML\n",
    "df_list[1].to_html('country.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Data from parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read parquet file\n",
    "employee_df1 = pd.read_parquet('employee.parquet', engine='pyarrow', columns=['ename', 'designation','salary'])\n",
    "\n",
    "employee_df2 = pd.read_parquet('employee.parquet', engine='fastparquet', columns= ['ename', 'designation','salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a parquet file.\n",
    "customer_df.to_parquet('customer.parquet', engine='pyarrow')\n",
    "\n",
    "customer_df.to_parquet('customer.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Data from Pickle Pandas Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read DataFrame object from pickle file\n",
    "pd.read_pickle('foo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame object in pickle file\n",
    "df.to_pickle('foo1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightweight access with sqllite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sqlite3\n",
    "import sqlite3\n",
    "\n",
    "# Create connection. This will create the connection with employee database.\n",
    "# If the database does not exist it will create the database\n",
    "conn = sqlite3.connect('employee.db')\n",
    "\n",
    "# Create cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute SQL query and create the database table\n",
    "cur.execute(\"create table emp(eid int,salary int)\")\n",
    "\n",
    "# Execute SQL query and Write the data into database\n",
    "cur.execute(\"insert into emp values(105, 57000)\")\n",
    "\n",
    "# commit the transaction\n",
    "con.commit()\n",
    "\n",
    "# Execute SQL query and Read the data from the database\n",
    "cur.execute('select * from emp')\n",
    "\n",
    "# Fetch records\n",
    "print(cur.fetchall())\n",
    "\n",
    "# Close the Database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Data from MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymysql connector module\n",
    "import pymysql\n",
    "\n",
    "# Create a connection object using connect() method with parameters IP Address, user name, password, database name, character set and cursor type.\n",
    "\n",
    "connection = pymysql.connect(host='localhost', # IP address of the MySQL database server\n",
    "                             user='root', # user name\n",
    "                             password='12345', # password\n",
    "                             db='emp', # database name\n",
    "                             charset='utf8mb4', # character set\n",
    "                             cursorclass=pymysql.cursors.DictCursor) # cursor type\n",
    "\n",
    "try:\n",
    "    with connection.cursor() as cur:\n",
    "        # Inject a record in database\n",
    "        sql_query = \"INSERT INTO `emp` (`eid`, `salary`) VALUES (%s, %s)\"\n",
    "        cur.execute(sql_query, (104,43000))\n",
    "\n",
    "\n",
    "    # Execution will not commit records automatically. We need to commit the record insertion explicitly.\n",
    "    connection.commit()\n",
    "\n",
    "    with connection.cursor() as cur:\n",
    "        # Read records from employee table\n",
    "        sql_query = \"SELECT * FROM `emp`\"\n",
    "        cur.execute(sql_query )\n",
    "        table_data = cursor.fetchall()\n",
    "        print(table_data)\n",
    "\n",
    "except:\n",
    "    print(\"Exception Occurred\")\n",
    "finally:\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required connector\n",
    "import mysql.connector\n",
    "\n",
    "# Establish a database connection to mysql\n",
    "connection=mysql.connector.connect(user='root',password='12345',host='localhost',database='employee')\n",
    "\n",
    "# Create a cursor\n",
    "cur=connection.cursor()\n",
    "\n",
    "# Running sql query\n",
    "cur.execute(\"select * from emp\")\n",
    "\n",
    "# Fetch all the records and print it one by one using for loop\n",
    "for i in cur.fetchall():\n",
    "    print(i)\n",
    "\n",
    "# Create a DataFrame from fetched records.\n",
    "df = pd.DataFrame(cur.fetchall())\n",
    "\n",
    "# Assign column names to DataFrame\n",
    "df.columns = [i[0] for i in cur.description]\n",
    "\n",
    "# close the connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sqlalchemy engine\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Instantiate engine object\n",
    "en = create_engine(\"mysql+pymysql://{user}:{pw}@localhost/{db}\"\n",
    "                .format(user=\"root\", \n",
    "                        pw=\"abc@123\", \n",
    "                        db=\"emp\"))\n",
    "\n",
    "# Insert the whole dataframe into the database using to_sql() with the table name, if_exists and chunksize parameter\n",
    "\n",
    "df.to_sql('emp', con=en, if_exists='append',chunksize=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Data from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pymongo\n",
    "import pymongo\n",
    "\n",
    "# Create mongo client\n",
    "client = pymongo.MongoClient()\n",
    "\n",
    "# Get database\n",
    "db = client.employee\n",
    "\n",
    "# Get the collection from database\n",
    "collection = db.emp\n",
    "\n",
    "employee_salary = {\"eid\":114, \"salary\":25000}\n",
    "\n",
    "# Write the data using insert_one() method\n",
    "collection.insert_one(employee_salary)\n",
    "\n",
    "# Read the data from collection and assigns fetched data to pandas DataFrame\n",
    "data = pd.DataFrame(list(collection.find()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Data from Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the cluster\n",
    "from cassandra.cluster import Cluster\n",
    "\n",
    "# Creating a cluster object\n",
    "cluster = Cluster()\n",
    "\n",
    "# Create connections by calling Cluster.connect():\n",
    "conn = cluster.connect()\n",
    "\n",
    "# Execute the insert query\n",
    "session.execute(\n",
    " \"\"\" INSERT INTO users (eid, ename, age) VALUES (%(eid)s, %(ename)s, %(age)s, %(name)s)\"\"\", \n",
    " {'eid':101, 'ename': \"Steve smith\", 'age': 42})\n",
    "\n",
    "# Execute the select query\n",
    "rows = conn.execute('SELECT * FROM users')\n",
    "\n",
    "# Print the results\n",
    "for emp_row in rows:\n",
    "    print(emp_row.eid, emp_row.ename, emp_row.age)\n",
    "\n",
    "# Create a dataframe and assign fetched data to DataFrame\n",
    "data = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Data from Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "# Import module\n",
    "import redis\n",
    "\n",
    "# Create connection\n",
    "r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "\n",
    "# Setting key-value pair\n",
    "r.set('eid', '101')\n",
    "\n",
    "# Get value for given key\n",
    "value=r.get('eid')\n",
    "\n",
    "# Print the value\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pony ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pony module\n",
    "from pony.orm import *\n",
    "\n",
    "# Create database\n",
    "db = Database()\n",
    "\n",
    "# Define entities\n",
    "class Emp(db.Entity):\n",
    "    eid = PrimaryKey(int,auto=True)\n",
    "    salary = Required(int)\n",
    "\n",
    "# Check entity definition\n",
    "show(Emp)\n",
    "\n",
    "# Bind entities to MySQL database\n",
    "db.bind('mysql', host='localhost', user='root', passwd='12345', db='employee')\n",
    "\n",
    "# Generate required mappings for entities\n",
    "db.generate_mapping(create_tables=True)\n",
    "\n",
    "# turn on the debug mode\n",
    "sql_debug(True)\n",
    "\n",
    "# Select the records from Emp entities or emp table\n",
    "select(e for e in Emp)[:]\n",
    "\n",
    "# Show the values of all the attribute\n",
    "select(e for e in Emp)[:].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
